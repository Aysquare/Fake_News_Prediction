 ### Importing the Dependencies

import numpy as np
import pandas as pd
import re                                            # Used for searching for words in a text or paragraph
from nltk.corpus import stopwords                    # Stopwords are words that adds no or much value to a paragraph or text
from nltk.stem.porter import PorterStemmer           # PorterStemmer gives the root word for words
from sklearn.metrics import accuracy_score
from sklearn.feature_extraction.text import TfidfVectorizer  ### TfidfVectorizer is used to convert text to numerical values
from sklearn.model_selection import train_test_split 
from sklearn.linear_model import LogisticRegression


import nltk
nltk.download('stopwords')

### Printing to see the list of stopwords

print(stopwords.words('english'))

### Data Pre-Processing

# loading the dataset into pandas Dataaframe

news_dataset = pd.read_csv('C:\\Users\\USER\\Desktop\\Kaggle\\Fake News.csv')

# Investigating the number of rows and columns

news_dataset.shape

# Printing the first 5 rows of the DataFrame

news_dataset.head()

# Investigating the number of missing values in each column

news_dataset.isnull().sum()

# Reolacing the null values with empty string

news_dataset = news_dataset.fillna('')

# Merging the author name and title

news_dataset['content'] = news_dataset['author'] + ' ' + news_dataset['title']

print(news_dataset['content'])

# Seperating the features from the target

X = news_dataset.drop(['label'], axis = 1)
Y = news_dataset['label']

print(X)

print(Y)

### Stemming:

stemming is the process of reducing a word to its root word.

Example: actor, acting, actress -----> act

port_stem = PorterStemmer()

def stemming(content):
    stemmed_content = re.sub('[^a-zA-Z]', ' ', content)
    stemmed_content = stemmed_content.lower()
    stemmed_content = stemmed_content.split()
    stemmed_content = [port_stem.stem(word) for word in stemmed_content if not word in stopwords.words('english')]
    stemmed_content = ' '.join(stemmed_content)
    return stemmed_content

news_dataset['content'] = news_dataset['content'].apply(stemming)

print(news_dataset['content'])

### Seperating the data and label

X = news_dataset['content'].values
Y = news_dataset['label'].values

print(X)

print(Y)

Y.shape

### Converting the textual data to numerical data
vectorizer = TfidfVectorizer()
vectorizer.fit(X)

X = vectorizer.transform(X)

print(X)

### Splitting the dataset into train and test data

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, stratify = Y, random_state = 2)

### Fitting and training the model

model = LogisticRegression()
model.fit(X_train, Y_train)


train_data_pred = model.predict(X_train)

accuracy = accuracy_score(Y_train, train_data_pred)
print('Accuracy score of train data: ', accuracy)

accuracy = accuracy_score( train_data_pred, Y_train)
print('Accuracy score of train data: ', accuracy)

test_data_pred = model.predict(X_test)
accuracy = accuracy_score(Y_test, test_data_pred)
print('Accuracy score of test data: ', accuracy)


